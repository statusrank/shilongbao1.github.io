---
title: 机器学习之逻辑回归总结
tags: 机器学习
abbrlink: 65fc542a
date: 2018-07-04 21:42:19
---
<h2>逻辑回归</h2>
此文章主要学习于吴恩达老师的Machine Learning 公开课。
<!--more -->
	逻辑回归主要用于**二分类**问题,eg 垃圾邮件识别，交易是否欺诈，是否恶性肿瘤等。
	也就是说这里我们的lable只有两类,y == 0 || y == 1.很多时候，我们希望我们的预测值输出范围在0～1之间，可以加入一个sigmoid函数(可以称为逻辑函数)，类似神经网络的激活函数，输出范围就控制在了0～1之间。
	sigmod函数:
		$ g(z) = \frac{1}{1 + e^{-z}}$
	从而假设函数如下:
		$ h_{\theta}(x) = \frac{1}{1 + e^{-\theta^Tx}}$
	{%asset_img 1.png%}


<font color = "red">假设函数的输出意义就是在输入X的情况下Y==1的概率。<font>

<h3>决策边界</h3>
	决策边界是假设函数的一个属性，有确定的参数值我们就可以直接得到决策边界。它不是数据集的属性
只要概率大于等于0.5，那么就当作y=1
	{%asset_img 2.png %}
如果假设函数是 （三个参数分别等于-3，1，1），所以参数向量就是（-3，1，1），则：决策边界的方程就是 x1+x2 = 3.
	{%asset_img 3.png %}

<h3>损失函数</h3>
	在之前线性回归的时候，我们使用的是差平方误差函数，我们能得到一个单弓形的凸函数，但是逻辑回归中，h函数是sigmoid函数，对应的J函数是左下角的形式，会形成很多局部最优解，用梯度下降的话就不能很好解决问题，因此需要换一个损失函数，希望它像右下角那样是单弓形的凸函数。
{%asset_img 4.png %}
我们选择的损失函数是对数函数：{%asset_img 5.png %}
	上面这个图像告诉我们如果实际值y=1，而我们的预测值也为1的话,那么我们的代价函数值就很小,接近于0.而如果实际值y=1而我们预测值是0的话,我们的代价函数值就很大。
{%asset_img 6.png %}
	同理,当y=0而我们的预测值h(x)也为0我们的代价同样也是很小的；如果预测值为1我们的代价就是很大的。至此,我们的代价函数能很好的反应我们的参数$\theta$ 对数据的你和情况,我们就可以根据代价函数的值来寻找最优的参数$\theta$来拟合数据。

*简化损失函数*
	{%asset_img 7.png %}

<h3>梯度下降</h3>
先来下梯度下降的推导:[可以看这个博客推导](https://www.cnblogs.com/zhongmiaozhimen/p/6155093.html)

{%asset_img 8.png %}
主要也是运用了链式法则，将下面的化简结果带入上式即可。
{%asset_img 9.png %}、
最终的梯度下降:
{%asset_img 10.png %}

<h3>将逻辑回归应用到多分类中</h3>
例如下面一个三分类问题,我们可以构造三个分类器$h_1,h_2,h_3$
{%asset_img 11.png %}

最后对于输入的x,我们预测它的分类只需要在所有的分类器中找最大值即可。
	$ max_i h_{\theta (x)$

<h3>代码实现</h3>
```
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd
from numpy.linalg import inv
import matplotlib.pyplot as plt 
"""
构建Logistic Regression Function , h(x) = 1 / (1 + exp(-wx))，对是否为setosa进行分类
Cost Function J(theta) is 1/m sigma(-ylog(h(x) - (1 - y)log(1 - h(x)))) 
"""

def sigmoid(x):
    return 1.0/(1 + np.exp(-x))


#梯度下降
def GradientDescent(X,Y,alpha,theta,maxIteraton,J):
    m,n = X.shape
    for i in range(maxIteraton):
        hypothesis = sigmoid(np.dot(X,theta))
        #计算损失函数值
        J[i] = -(1.0 / m)*np.sum(Y*np.log(hypothesis) + (1 - Y) * np.log(1 - hypothesis))
        loss = hypothesis - Y
        gradient = np.dot(X.T,loss) / m
        theta = theta - alpha * gradient
    return theta,J
"""
牛顿迭代法,使收敛的速度更快
"""

#预测
def predict(X,theta):
    m,n = X.shape
    Xtest = np.ones((m,n + 1))
    Xtest[:,:-1] = X
    Ytest = sigmoid(np.dot(Xtest,theta))
    Y_pre = []
    for i in Ytest:
        if i >= 0.5:
            Y_pre.append(1)
        else:
            Y_pre.append(0)
    return Y_pre
if __name__ == '__main__':
    
    datapath = r'C:\Users\shilongbao\assignment1\iris\iris.csv'
    #读取数据
    iris = pd.read_csv(datapath)
    # 获得虚拟变量（哑变量）；也就是将当前所拥有的值扩充为一个矩阵,在自己对应的位置置1,其余的置0
    dummy = pd.get_dummies(iris['Species'])
    # 将两个矩阵连接起来
    iris = pd.concat([iris,dummy],axis = 1)
    #Y_trian = iris.iloc[113,'setosa']
    #print(X_train)
    #print(Y_trian)
    #iloc 截取样本(按行按列)
    iris = iris.iloc[0:100,:]
    #print(iris)


    temp = pd.DataFrame(iris.iloc[:,1:])
    #print(temp)
    X = temp.iloc[:,:4]
    X['x0'] = 1
    #print(X)
    Y = np.reshape(iris['setosa'],len(iris),1)
    print(Y.shape)
    m,n = X.shape
    #print("%d %d"%(m,n))
    theta = np.ones(n)
    #print(theta)
    alpha = 0.001 # 选择学习率
    maxIteraton = 3000
    J = pd.Series(np.arange(maxIteraton,dtype = float))
    theta,J = GradientDescent(X,Y,alpha,theta,maxIteraton,J)
    print(theta)
    J.plot()
    X_train = [6.8,3.0,5.5,2.1] # 简单的测试
    X_train = np.array(X_train).reshape(1,4)
    Y_train = np.array([0]).reshape(1)
    Y_pre = predict(X_train,theta)
    if Y_pre[0] == Y_train[0]:
        print("correct!")
    else:
        print("wrong!")
        
```


