---
title: A Scalable Probabilistic Tensor Factorization(SPTF)
copyright: true
mathjax: true
tags:
  - RS
categories: 推荐
abbrlink: 33a62389
date: 2018-11-14 18:51:56
updated:
---
[论文](http://net.pku.edu.cn/daim/hongzhi.yin/papers/ICDM17.pdf)
[知乎上的中文回答](https://zhuanlan.zhihu.com/p/36109076)
SPTF具体来说还是基于张量分解TF的一种方法,同时也还是基于score learning的。
<!--more-->

##介绍
用户历史行为可以被分为两种类型: 显示反馈(explicit feedback)和隐式反馈(implicit feedback). explicit feedback包括用户关于他们感兴趣的item的显示输入,主要体现在对item的rating(评分)。但是explicit feedback并不总是能够获得。更多的情况下,隐式评分通过用户的行为例如点击或不点击,买或不买等表达出来,这些更容易常见也更容易获得。** 关于implicic feedback的一个缺陷就是只有正反馈我们才能观察到(比如user点击了某件item,或者购买了item等,对于不点击和不购买我们无法获知,且那些negative中并不是所有的都是对此不感兴趣,也可能user暂时不买,以后会买等)**。仅仅根据上面所说的正样例或者可观察到的协同过滤(CF)我们成为one-class Collaborative Filtering(OCCF).
现在很多工作集中在同质的用户行为上,并没有考虑到现实世界中用户行为的多样性和异质性。比如,典型的电商平台中用户的行为类型最少有四种(点击,加入购物车,收藏,购买)。**不同的用户行为类型暗示着不同的语义和用户意图。**人们和item交互的方式在理解用户意图和建模用户兴趣时是关键。也就是说我们关注的不是用户和什么交互了,而是用户怎样和item交互。另外,在单一行为类型上的(例如购买)用户隐式反馈数据是很稀疏的,因此，必须集体利用丰富的异构行为数据来增强每种类型的行为预测，尤其是对稀疏行为类型的预测（例如，购买预测）。
在这个论文中作者提出了SPTF模型,每个用户行为记录都是三元组(user,type,item)表示而不是二元组,我们区分不同的行为类型因为他们传达了不同的语义。SPTF为每个user,item,type学习潜在的向量表示。张量是对象之间多种关系的有用方式，张量因子分解被视为预测未来他们可能关系的重要手段。但是现存的TF模型如BPTF何RESCAL忽视了所有的未观察的样本,正如MF对explicit feedback 所做的那样。
为了解决这个问题作者提出了**非负采样技术。**那些未观察到的样本,例如用户没有购买某个item等,是**真正负样本(例如用户对某个item不感兴趣)和潜在的正样本(用户在未来可能会想买这个item)的混合**。这对确定真正具有代表性的负面例子来说十分有挑战性。一个广泛采用的方案是把所有未观察到的样本全部看成是负样本,这种方案在小数据上运行良好比如 weighted MF 和 BPR-based。但是这种方法会限制预测的准确率,因为一些丢失的数据可能是正的。而且这种方法无法用到大规模数据上,计算量大。
另外,在这个问题当中用户行为是异构的,正样例的分布是非常不均匀的。比如在数据中点击动作类型所占数据的比例大,其他的动作比较少等。如果这样训练下去的话最后训练出来的model可能会很大程度偏向于预测click。据此,作者提出了适应性基于排序的采样方法,主要思想就是在low-rank的正样例应该有更高的概率被采样,因为这种正样本存在更多的信息同时对修正当前模型的参数很有帮助，
###主要贡献
1.本文提出了语义感知的用户行为预测的研究问题，目的是为了预测用户某种特定行为下最有可能的top-n个产品。
2.提出了一种可大规模扩展的基于概率的张量分解模型，用于建模可以感知语义多样性的用户行为数据。提出了双向流行度偏差化负例采样方法来优化该模型。
3.提出了一种适应性基于排序的正例采样策略用于生成训练数据。

##模型描述
user集合$U = \{u_1,u_2,...u_I\}$ 
item集合$V = \{v_1,v_2,...v_J\}$ 
behavior集合$ T = \{t_1,t_2,...t_K\}$
$x(i,j,k)$表示一条行为记录。
{%asset_img 1.png %}

我们的目标是:** 给定一个目标用户和操作类型,我们去预测$u_i$执行动作$t_k$时最优可能的前N个item**
每种用户，商品，行为类别被表示为一个D维的隐向量，$y(i,j,k) $表示一组用户行为信息,用$u_i,v_j,t_k$表示,$ \theta = \{u_i,t_k,v_j\}$代表我们的模型参数.我们的得分函数$f$,用来预测$x(i,k,j)$的存在,他表示了在给定参数$\theta$，三元组$x(i,k,j)$存在的置信度。{%asset_img 2.png %}

公式2理解为,所有的用户行为数据 $y_{ijk}$是基于独立条件概率于给定的user,item,behavior的隐向量。模型通过一个评分方程$f(x_{ijk};\Theta)$来建模一组用户数据$x_{ikj}$的存在性，评分方程表示了模型的confidence。 $\sigma(x) = \frac{1}{(1+e^{-x})}$ 为sigmoid逻辑函数,它将评分函数映射到(0,1)之间从而表示概率。$Ber(y|p)$为伯努利分布,表示为:{%asset_img 3.png %}
多种张量分解模型TF,CP,Pairwise Interaction Factorization (PIF)可以用来实现提出的SPTF模型,此工作采用了PIF:
{%asset_img 4.png %}
根据概率矩阵分解成功的经验,我们在被优化参数上采用高斯先验分布,模型的概率生成如下:
{%asset_img 5.png %}
基于上面我们模型的概率生成过程,通过简单的[贝叶斯推断](https://www.cnblogs.com/hxsyl/p/4876465.html),user,item,behavior的隐向量的后验分布如下:
{% asset_img 6.png %}
U, V, T 是由 u, v, t为列向量所构成的矩阵。优化目标是最大化公式5种的似然函数，其等价于公式6种最小化负对数似然函数。
##模型优化
直接优化Eq(6)的代价非常昂贵,因为数据中未观测到的数据为3次方用户或商品的数量。同时,**并不是所有的未观察的样本都是真正的负样本。因此,从负样本采样得到了灵感,相对于利用所有未观测的样本,作者选择一些最有可能的负样本来优化模型。**
###双向负例采样
采样的概率非常重要,现有的负采样方法都只替换triple的一边来构建负例,称为统一方向采样。
具体的说,比如给定一组用户交互行为$(u_i,t_k,v_j)$，大多数目前的方法通过固定$u_i,t_k$同时根据一个噪声比例替换$v_j$来构建负例(寻找那些$u_i$对$v_j$从未有过$t_k$的item)。
如果我们只从用户角度去构建负例,如同BPR方法里的那样，那么模型就不能准确的学习到商品V的隐向量。因为在这种情况下,只有正的用户(用户i对商品j有过t行为)被考虑到，因此学习到的商品v的隐向量则不能分别其正用户和负用户。
本文采用的双向负例菜一样方法,首先固定$u,t$采样$v$,然后固定$t,v$采样$u$。然后该如何决定**采样概率**呢?为此作者提出如下负采样方法:
1.Popularity-biased Item Sampling (PIS): 采用{%asset_img 7.png %}作为负采样item的概率分布。$ \sum_i Y(i,k,n)$表示动作$t_k$下的$v_n$的流行度。**给定一个user,它未通过$t_k$和这些受欢迎的items交互,就有很高的概率是真正的负样例。**
2.Popularity-biased User Sampling (PUS):采用{%asset_img 8.png %}作为负采样user的概率分布。那些通过动作$t_k$和许多items交互,但是未和此$v_j$交互的，就有很高的概率对$v_j$不感兴趣。
$N$为对一个正例$(u_i,t_k,v_j)$采样负item和负user的数量，我们的目标函数如下:
{%asset_img 9.png %}
因此任务就是使用逻辑回归的方法将正例从他们相应的负例中区分开。
我们的目标函数如下:
{%asset_img 10.png %}
算法流程:{%asset_img 11.png %}
###适应性正样本采样策略
由于用户行为数据是多种多样的,并且对于每种行为,其分布也是广泛不均匀的。大多数优化算法在优化过程中,默认所有的行为数据分布是均匀的,这就会产生问题，比如占比重大的用户行为类型数据将会被采样的非常多,相对来说一部分占比较少的用户行为记录将会被采样的非常少。这样的后果就是,**占比多的交互行为类别将会被预测的非常准确,而那些分布比较少的行为类型预测精度就会不足。**
此外即使对于相同类型的用户行为,每个正例的重要性和信息性也是不相同的,并且可能在模型训练中发生变化。我们期望的正采样器选择那些当前学习状态下信息性强(对于当前的模型参数集$\Theta$)并且对修正模型更有帮助的高概率的正例。(至于为什么适应性正采样可以这里我有点懵。。)
因此本文提出为每个正例计算出一个权重:{%asset_img 12.png%} 
然后采样概率计算如下:{% asset_img 13.png %}
作者提出使用连续采样程序去重复采样负例直到我们找到一个负例$x(i,k,n)$它的得分比$x(i,k,j)$大来估计$rank(i,k,j)$。这样的负例我们叫做imposter，$Nikj$表示我们需要 采样多少个负例才能找到一个imposter,则$rank(i,k,j)$近似为
$ \lfloor \frac{Nik + 1}{Nikj}\rfloor$ 
{% asset_img 14.png %}
###语义感知用户行为预测
一旦我们的模型参数$\Theta$被估计好后,我们就可以进行语义感知用户行为预测。也就是说,给定我们一个$u_i$和动作$t_k$我们根据$f$算出的得分去预测$u_i$在动作$t_k$下的top-n items。
##Experiment

此实验使用了Tmall 2014年公开的数据集,大约有2000w条记录。
###Data Format
```python
	user_id item_id action_type
    '''
    user_id 标识唯一user
    item_id 标识唯一item
    action_type = {1,2,3,4} 分别表示 click,add-to-favorite,add-to-cart,purchase
    另外paper中提到原数据中应该还有timestamps 字段,是该交互行为发生的时间。但是在公开的dataset中并没有。
    '''
```
###预测准确率的评估
所有观察到的implicit feedback 组成的集合为$ D^+$ ，我们根据其中的timestamps字段就行排序,然后将我们的数据集分为 $Train/test/validation = 80/10/10 \%$. 
####命中率 Hits ratio
为了评估预测模型,采用了推荐系统和知识图舍去广泛采用的方法**命中率 Hits ratio**.
**如何计算命中率?** 对于每个$x_{ikj} \in D^+_{test} , x_{ikj} = (u_i,t_k,v_j)$: 
1.我们首先随机选择10000件 item $v_l$, 要求:$u_i$从未对$v_l$有过$t_k$动作。选择这样10000个triplet $(u_i,t_k,v_l)$ 组成我们的负样本。
2.根据Eq(4)的基于PIF的得分函数我们计算这10001个triplet的score。
3.根据他们的score进行排序,组成一个ranked list .设 $rank(x_{ikj})$表示正例$x_{ikj}$ranked list中的排名。
4.我们从ranked list中选择前n个来组成我们预测的Top-n item. 如果
$ rand(x_{ikj}) <= n$,那么就是命中,否则就是不命中。
Hits ratio计算公式如下:
{% asset_img 15.png %}
hit@n : 对于单个$xikj$ 如果其$ rank <= n$即被选中就是1,,否则为0
\#hit@n 即为所有hit@n的和，所以可以看出Hits@n其实就是hit@n的均值。
**我们还可以将数据根据action type 分为4组三元组,这样可以进一步分析对于每种特定类型的用户行为预测的性能。** 
####Mean Reciprocal Rank(MRR)
MRR是平均倒数排序的简称。MRR方法计算每一个查询中第一个相关结果位置的倒数。(在这里就是我们的每一个$x_{ikj}$ 在ranked list中的rank的倒数)
定义如下:
{%asset_img 16.png %}
MRR是所有正样例在其所有采样的负样例中的rank的倒数。显然一个好的预测模型应该有更大的MRR值。
####超参数优化
[网格搜索与交叉验证](https://blog.csdn.net/hdu_lazy_man/article/details/79590598)
使用网格搜索方法去寻找最优超参数得到 $ D = 50, λ_U = 0.001, λ_T = 0.0001, λ_V = 0.01$ 
$ D $ 为潜在向量空间的维度。
####评估模型的效率和可扩展性
除了预测准确性之外，我们还根据时间成本评估模型训练的效率。 由于采用异步随机梯度下降算法进行模型优化，我们还通过改变线程数来测试模型训练过程的加速比。
###对比方法
主要是比较了一些TF和MF的方法。
大体瞟了一眼引用paper,发现作者比较的TF和MF的方法稍微比较古老,所以原理啥的暂时不看了,只是看了一下为什么SPTF优于他们。
1.BPTF
BPTF是设计在显示反馈数据集的得分预测,它只考虑了可以观察到的样例。
2.RESCAL 
RESCAL是用于分解知识图的最先进的张量分解模型。 与BPTF不同，“predicate”（例如，我们问题中的行为类型）由矩阵而不是向量表示。 因此，它具有更强大的表达能力和更多的参数来估计。 同样的，RESCAL只从观察到的例子中学习。
3.BPR-PITF 
BPR-PITF是Tucker分解的一个特例,它明确的建模了user，item，type之间的成对交互。 通过贝叶斯个性化排名（BPR）标准的适应来学习该模型。**在此模型中,所有未观察的例子都被看成是负例,并且每个训练案例都是均匀的。(也就是说每个正例被选择的概率是相等的)。**尽管SPTF选择了同样的成对交互方法去分解张量,但是通过不同的损失函数和优化方法来学习模型。另外,SPTF并没有将所有的未观察的例子全部看成负例,而是使用双向流行度偏差负采样方法来选择那些更有可能的负样例,还使用了基于自适应排序的正抽样方法去解决数据集中action type的不均匀问题。
4.BPR-SMF 
与BPR-PITF相比，BPR-SMF是单独的基于BPR的矩阵分解。这里四个user-item 的矩阵，每个矩阵存储一种特定类型的用户行为。我们将基于BPR的矩阵分解模型分别用于每个矩阵,并且为每个user或item学习4个潜在的向量,这些向量分别与他们的4种action type 对应。因此，相同用户或项目的潜在向量不在四个矩阵中共享。 我们采用基于BPR的矩阵分解模型，因为它在one-class协同过滤(OCCF)中具有出色的性能。

作者使用四个SPTF变体(也就是控制变量法)来研究SPTF所提出的几种方法的性能。
如图:
{% asset_img 17.png %}
###Effectiveness of Semantic-Aware User Behavior Prediction
下面是SPTF与上面提到的四种方法的关于$\#Hit@n$的比较,我们只比较了Top-n，n分别为1,5,10,15,20.当n再大通常没有意义。可以看出在n<=5时 对于命中率的提升最明显。
{% asset_img 18.png %}
通过上面我们发现：
1.SPTF,BPR-PITF和BPR-SMF的预测准确率比BPTF和RESCAL更高,**因为这三种方法都使用了负例,而RESCAL和BPTF都只考虑了正例。**BPTF只是对于显示得分的预测。
2.SPTF和BPR-PITF比BPR-SMF要好。**这证明了在多种关系数据上的整体分解建模要比基于独立分解的方法好，因为整体分解模型通过在所有关系中共享同样的潜在向量能够有效的解决数据稀疏的问题。**
3.BPR_SMF在click行为上的预测要好于其在其他三种type上的预测,因为我们有充足的关于click action的训练数据
4.尽管SPTF和BPR_PITF使用同样的pair-wise张量分解方法,但是他们两个采用了不同的负采样方法（BPR_PITF将所有未观察到的全部看成负的）和不同的正采样策略。
5.另外，五种方法的MRR和他们的命中率高度一致:
{%asset_img 19.png %}
###不同因素的影响
####不同采样策略分析
主要讨论了SPTF提出的三种方法: 基于流行度偏差负采样、双向负采样以及适应的基于排序的正采样。
Figure2展示了对于Table2的五种SPTF的比较结果。
{%asset_img 20.png %}

####敏感性分析
这一部分作者讨论了SPTF中的超参数,包括负例的个数N,随机梯度下降的步数M,训练样例的个数以及在适应性基于排序的采样方法中我们采样负例的个数$ N_{ikj}$ .
如图: {%asset_img 21.png %}
可以看到当$ N>=4 $时,开始变得稳定了。
下图展示了$N_{ikj}$ 的个数
{% asset_img 22.png %}
可以看出当$ N_{ikj} >= 15$变得逐渐稳定。
下图展示了随机梯度下降的步数M,当$ M >= 300000000$就收敛了。
{%asset_img 22.png %}
###效率和可扩展性的评估
这里主要讲的是在GPUs上的线程数与预测准确率 还有加速比,以及同等硬件环境下的上述四种方法与SPTF训练所需要的时间。。
###行为语义的相似性分析
**这里主要研究了任意两种类型的用户行为之间的语义相似性。**主要是研究了学习到的四种行为类型的潜在向量之间的相似度.给定任意两个action type $ t_i,t_j$ ，计算出他们的内积以及欧式距离来表示他们之间的相似度。 结果如下:{% asset_img 24.png %}
可以看出加入购物车和收藏与购买之间的相似度较大,这意味着添加到收藏夹和添加到购物车的行为数据具有更强大的潜力来改善用户购买行为的预测。同时也发现添加到收藏夹与购买之间的相似度比添加到购物车与购买之间的相似度要大。

