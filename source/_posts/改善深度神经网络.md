---
title: deeplearning.ai 改善深度神经网络(正则化、优化、mini-batch等)
tags: Deep Learning
copyright: true
mathjax: true
categories: 深度学习
abbrlink: 65d241ff
date: 2018-08-15 11:09:42
updated:
---

[作业地址可查看github](https://github.com/statusrank/deeplearning.ai-note)
##一、初始化
###1.为什么神经网络的所有参数不能全部初始化为0>?
若w初始化为0 ,很可能导致模型失效,无法收敛。也就是说如果我们初始将所有的w初始化为0,那么进行前向传播时每一层得到的值都是一样,这样一来当我们使用反向传播时,传回的梯度也是一样的,这就导致了我们更新参数后w还是一样的,这就使得我们的NN不能各自学习到很好的特征了。[可以看这里](https://zhuanlan.zhihu.com/p/27190255)
<!--more-->
###2.Xavier Initialization
  Xavier Initialization 初始化的基本思想就是保持输入和输出的方差一致,这样就避免了所有的输出值趋向于0.
  首先对于前向传播,我们需要确保所有层的激活值方差近似相等,因此每个训练样本传播经过网络的信息才能保持平滑的属性。同样对于反向传播,每层梯度保持近似的方差将允许信息平滑地反向流动以更新权重。近似方差的梯度同样确保误差数据能够反馈到所有层级,因此它是整个训练中的关键。
[这位大佬写的很不错](https://www.jiqizhixin.com/articles/2018-01-08-3)

将W的方差变为 $ \frac{1}{layersdims[l - 1]} $

###3.He Initialization

He Initialization 在使用Relu作为非线性激活函数时具有更好的效果,因为Relu函数将所有的负数都变为0,所以W的整体的方差需要变为原来的二倍，$ \frac{2}{layersdims[l - 1]} $

##二、正则化

###1.什么是过拟合(overfitting)?
过拟合就是指在我们的训练数据中存在一些噪声,而我们的模型拟合的很好将这些噪声也都给拟合进去了,使我们的分类器过于严格。这时候我们得到的参数往往就对我们的train data表现的很好,对其他数据表现的很差。

###2.L2 Regularization
L2正则化,又叫L2范式。基本格式: $ \frac{\lambda}{2}\sum_i^{m} W_i^2 $ (除2是为了求导时抵消)
也就是把我们所有的参数,都加入一个平方的乘法项，因为加入了平方惩罚项,所以在进行拟合时我们使得所有得到的参数都比较小,我们一般认为参数小的模型都比较简单可以适应不同的数据集,从而一定程度上避免了过拟合。
但是同时这里也增加了一个超参数 $ \lambda $

###3.Dropout
Dropout在深度学习中是一种广泛使用的技术。在每一层中,他会以一定的概率使一些神经元停止工作,这样使得各个神经元之间不相互依赖,从而提高模型的泛化能力。
每一个神经元有一个将其保留下来的概率,keep_prob(每一层的概率不一定相同)，那么当你在进行每一次迭代的时候对每一层的每个神经元你都有一定的概率(1 - keep_prob)，也就是将其激活值置为0,停止的神经元对后面的前向传播和反向传播不起作用。
**注意在输入和输出层我们不需要使用dropout**
Dropout的实现:
  (1) 通过np.random.randn()初始化一个和A^L 一样的矩阵,并将此看为把每个神经元保留的概率
  (2) D = D <= keep_prob
  (3) A = A * D (数乘,一一对应)
  (4) $ A = \frac{A}{keep_prob} $ 通过这一步使得loss的期望值和没有dropout时是一样的

与此同时,在进行反向传播时也需要做同样的操作
<font color = "red">使用Dropout需要注意以下几点:</font>
  Dropout是一种正则化技术
  只是在训练阶段使用dropout,在test时不要使用
  记得需要除以 keep_prob从而使得期望值不变
```python
 GRADED FUNCTION: forward_propagation_with_dropout

def forward_propagation_with_dropout(X, parameters, keep_prob = 0.5):
    """
    Implements the forward propagation: LINEAR -> RELU + DROPOUT -> LINEAR -> RELU + DROPOUT -> LINEAR -> SIGMOID.
    
    Arguments:
    X -- input dataset, of shape (2, number of examples)
    parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3":
                    W1 -- weight matrix of shape (20, 2)
                    b1 -- bias vector of shape (20, 1)
                    W2 -- weight matrix of shape (3, 20)
                    b2 -- bias vector of shape (3, 1)
                    W3 -- weight matrix of shape (1, 3)
                    b3 -- bias vector of shape (1, 1)
    keep_prob - probability of keeping a neuron active during drop-out, scalar
    
    Returns:
    A3 -- last activation value, output of the forward propagation, of shape (1,1)
    cache -- tuple, information stored for computing the backward propagation
    """
    
    np.random.seed(1)
    
    # retrieve parameters
    W1 = parameters['W1']
    b1 = parameters['b1']
    W2 = parameters['W2']
    b2 = parameters['b2']
    W3 = parameters['W3']
    b3 = parameters['b3']
    
    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID
    Z1 = np.dot(W1, X) + b1
    A1 = relu(Z1)
    ### START CODE HERE ### (approx. 4 lines)         # Steps 1-4 below correspond to the Steps 1-4 described above. 
    D1 = np.random.rand(A1.shape[0],A1.shape[1])    # Step 1: initialize matrix D1 = np.random.rand(..., ...)
    D1 = (D1 <= keep_prob)                              # Step 2: convert entries of D1 to 0 or 1 (using keep_prob as the threshold)
    A1 = A1 * D1                                   # Step 3: shut down some neurons of A1
    A1 = A1 / keep_prob                               # Step 4: scale the value of neurons that haven't been shut down
    ### END CODE HERE ###
    Z2 = np.dot(W2, A1) + b2
    A2 = relu(Z2)
    ### START CODE HERE ### (approx. 4 lines)
    D2 = np.random.rand(A2.shape[0],A2.shape[1])     # Step 1: initialize matrix D2 = np.random.rand(..., ...)
    D2 = (D2 <= keep_prob)                              # Step 2: convert entries of D2 to 0 or 1 (using keep_prob as the threshold)
    A2 = A2 * D2                                    # Step 3: shut down some neurons of A2
    A2 = A2 / keep_prob                              # Step 4: scale the value of neurons that haven't been shut down
    ### END CODE HERE ###
    Z3 = np.dot(W3, A2) + b3
    A3 = sigmoid(Z3)
    
    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)
    
    return A3, cache

```
代码:
```
# GRADED FUNCTION: backward_propagation_with_dropout

def backward_propagation_with_dropout(X, Y, cache, keep_prob):
    """
    Implements the backward propagation of our baseline model to which we added dropout.
    
    Arguments:
    X -- input dataset, of shape (2, number of examples)
    Y -- "true" labels vector, of shape (output size, number of examples)
    cache -- cache output from forward_propagation_with_dropout()
    keep_prob - probability of keeping a neuron active during drop-out, scalar
    
    Returns:
    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables
    """
    
    m = X.shape[1]
    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache
    
    dZ3 = A3 - Y
    dW3 = 1./m * np.dot(dZ3, A2.T)
    db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True)
    dA2 = np.dot(W3.T, dZ3)
    ### START CODE HERE ### (≈ 2 lines of code)
    dA2 = dA2 * D2 # Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation
    dA2 = dA2 / keep_prob       # Step 2: Scale the value of neurons that haven't been shut down
    ### END CODE HERE ###
    dZ2 = np.multiply(dA2, np.int64(A2 > 0))
    dW2 = 1./m * np.dot(dZ2, A1.T)
    db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True)
    
    dA1 = np.dot(W2.T, dZ2)
    ### START CODE HERE ### (≈ 2 lines of code)
    dA1 = dA1 * D1              # Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation
    dA1 = dA1 / keep_prob             # Step 2: Scale the value of neurons that haven't been shut down
    ### END CODE HERE ###
    dZ1 = np.multiply(dA1, np.int64(A1 > 0))
    dW1 = 1./m * np.dot(dZ1, X.T)
    db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)
    
    gradients = {"dZ3": dZ3, "dW3": dW3, "db3": db3,"dA2": dA2,
                 "dZ2": dZ2, "dW2": dW2, "db2": db2, "dA1": dA1, 
                 "dZ1": dZ1, "dW1": dW1, "db1": db1}
    
    return gradients
```

##三、优化
###1.Mini_batch Gradient descent

1.首先需要介绍Batch gradient descent，即完全采用全数据集的形式,由全数据集确定的方向能更好的代表样本总体,从而更准确的朝极值的方向。但是由于数据的海量增长和内存的限制,一次性载入全部的数据变得异常困难。
2.stochastic gradient descent，随机梯度下降,每次只采用一个样本进行梯度下降。这大大减少了训练时间,但是以每个样本各自的梯度方向修正,横冲直撞各自为政很难最后达到收敛。
3.这时候就产生了Mini——batch gradient descent.他是介于Batch gradient descent 和stochastic gradient descent之间的一种方法。当数据量很小时,我们直接采用Batch gradient descent ,当数据量很大时我们采用mini-batch,这时候每一个mini-batch的大小,我们称为batch_size。
其实当batch_size = m 就是batch gradient descent ,batch_size = 1 就是stochastic gradient descent.

常用的batch——size大小为: 64,128,256,512 一般为2的幂。

####为什么mini-batch有优势?
假设我们现在有100万样本,如果我们采用batch gradient descent 遍历一次所有的数据(epoch)只进行了一次迭代,如果我们将整个样本分成1000份,也就是batch_size = 1000,则会有1000个子集,然后当我们用for循环遍历这些子集时,针对每个子集进行一次梯度下降,这样当遍历完所有样本一次(epoch)我们相当于在梯度下降中进行了1000次迭代,这样就大大提高了我们算法的速度,同时因为每个子集只有1000个样本,也提高了内存的利用率。

#### mini_batch 的效果
{% asset_img 2.png %}
如上图，左边是full batch的梯度下降效果。 可以看到每一次迭代成本函数都呈现下降趋势，这是好的现象，说明我们w和b的设定一直再减少误差。 这样一直迭代下去我们就可以找到最优解。 右边是mini batch的梯度下降效果，可以看到它是上下波动的，成本函数的值有时高有时低,但是总体呈现下降的趋势。
这个也是正常的,<font color = "red">因为我们每一次梯度下降都是在mini_batch 上跑的而不是在整个数据集上,所以数据的差异可能会导致这样的效果，可能某段数据效果特别好,m藕断数据效果不好,但是他总体还是呈现下降趋势的。</font>
{% asset_img 1.png %}

<font color = "red">对于batch_size大小的选择，我们不能太大,因为太大会接近full batch的行为;也不能太小,太小了可能算法永远不会收敛。</font>

####mini_batch 实现

(1)为了避免偶然性,我们需要打乱我们的train data,通过np.random.permutation()随机打乱下标,并保存为list. 然后根据列表值重新获得矩阵.
(2)根据batch_size 大小进行划分.注意不能除尽的情况

```
# GRADED FUNCTION: random_mini_batches

def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):
    """
    Creates a list of random minibatches from (X, Y)
    
    Arguments:
    X -- input data, of shape (input size, number of examples)
    Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)
    mini_batch_size -- size of the mini-batches, integer
    
    Returns:
    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)
    """
    
    np.random.seed(seed)            # To make your "random" minibatches the same as ours
    m = X.shape[1]                  # number of training examples
    mini_batches = []
        
    # Step 1: Shuffle (X, Y)
    permutation = list(np.random.permutation(m)) # 随机打乱数组,permutation 参数可以是int,返回一个list
    shuffled_X = X[:, permutation]    # 按照permutation列表中的数字顺序作为下标重新得到一个列表,从而实现打乱矩阵的功能
    shuffled_Y = Y[:, permutation].reshape((1,m))
    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.
    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning
    for k in range(0, num_complete_minibatches):
        ### START CODE HERE ### (approx. 2 lines)
        mini_batch_X = shuffled_X[:,k * mini_batch_size : (k + 1) * mini_batch_size]
        mini_batch_Y = shuffled_Y[:,k * mini_batch_size : (k + 1) * mini_batch_size]
        ### END CODE HERE ###
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
    
    # Handling the end case (last mini-batch < mini_batch_size)
    if m % mini_batch_size != 0:
        ### START CODE HERE ### (approx. 2 lines)
        mini_batch_X = shuffled_X[:,num_complete_minibatches * mini_batch_size : m]
        mini_batch_Y = shuffled_Y[:,num_complete_minibatches * mini_batch_size : m]
        ### END CODE HERE ###
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
    
    return mini_batches
```

###2.momentum动量
因为mini_bacth梯度下降使参数每次只在子集上更新自己的参数,所以它每次下降的方向会有很多抖动,也就是说梯度下降会很大幅度的变动徘徊这向最低点前进(convergence 收敛)。使用momentum可以减少相应的抖动。
momentum会把过去的梯度考虑在内，使得梯度变的更平滑.
{% asset_img 3.png%}

####指数加权平均
举例说明，下面是一个同学的某一科的考试成绩： 
平时测验 80， 期中 90， 期末 95 
学校规定的科目成绩的计算方式是： 
平时测验占 20%； 
期中成绩占 30%； 
期末成绩占 50%； 
这里，每个成绩所占的比重叫做权数或权重。那么， 
加权平均值 = $80×0.2 + 90×0.3 + 95×0.5 = 90.5$ 
算数平均值 = (80 + 90 + 95)/3 = 88.3
另外一个例子,我们需要计算某地温度的移动平均值。
我们现在先直接给出一个公式 $V_t = \beta*V_{t-1} + (1 - \beta) \theta_t$ 其中$V_t$表示到第t天的平均温度值, $ \theta_t$ 表示第t填的温度值,$\beta$是可调节的超参数。
假设现在$\beta$值为0.9，那么大体就是前一日的v加上 0.1的今天的温度,对此我们可以理解为V的指数加权平均值约等于 $\frac{1}{1 - \beta} $ 也就是说大概 $\beta$ = 0.9 就是温度十天以来的加权平均值,$ \beta$ = 0.98就是50天以内的温度加权平均值.
{%asset_img 4.png%}
通过上面的表达式我们可以知道,$V_100$ 等于每天的温度乘以一个权值,本质就是以指数形式递减加权的移动平均,各数值的加权随时间而指数式递减,越近期的数据加权越重,而我们的算数平均每一项的权值都是 $\frac{1}{n}$


####偏差修正
首先给出带偏差修正的指数加权平均公式: 
$V_t = \beta V_{t-1} + (1-\beta)\theta_{t}$
$\hat(V_t) = \frac{V_t}{1-\beta^t} $
$ \frac{\beta V_{t-1} + (1-\beta)\theta_t}{1-\beta^t} $
随着t的增大,$ \beta^t $逐渐趋近于0,从而偏差修正不在起作用。
实际上,上面的例子在 $\beta = 0.98$时,实际上我们得到的不是绿色曲线,而是紫色曲线,因为使用指数加权平均的方法在前期会有很大的偏差,为此我们引入了偏差修正的概念。
{%asset_img 6.png %}
<font color = "red">在机器学习中,在计算指数加权平均数的大部分时候,大家不太在乎偏差修正,大部分宁愿熬过初始阶段,拿到具有偏差的估测,然后继续计算下去.
如果你关心初始时期的偏差,修正偏差能帮助你在早期获得更好的估测</font>

####momentum公式
以前我们在进行梯度下降时,对参数W更新, $ W = W - \alpha dw $,由于我们前面说过梯度下降会有很多抖动,所以这里我们就是在更新W的时候做些手脚。
$ V_{dw} = \beta V_{dw} + (1 - \beta)dw$
$ W = W - \alpha V_{dw}$
$V_{db} = \beta V_{db} + (1-beta)db $
$b = b - \alpha V_{db}$

$V_{dw},V_{db}$ 表示对w的导数dw,b的导数db求指数加权平均,然后更新参数时减去的是指数加权平均的值而不是导数的值。
关于 $ \beta$的值的选择,我们选择的值越大则结果越平滑,因为对过去的权重占的越多,对自己本身占的少,但是如果很大就超出我们想要的效果了。所以一般我们取 $\beta$ = 0.9

效果如图:{%asset_img 7.png %}
```python
 GRADED FUNCTION: update_parameters_with_momentum

def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):
    """
    Update parameters using Momentum
    
    Arguments:
    parameters -- python dictionary containing your parameters:
                    parameters['W' + str(l)] = Wl
                    parameters['b' + str(l)] = bl
    grads -- python dictionary containing your gradients for each parameters:
                    grads['dW' + str(l)] = dWl
                    grads['db' + str(l)] = dbl
    v -- python dictionary containing the current velocity:
                    v['dW' + str(l)] = ...
                    v['db' + str(l)] = ...
    beta -- the momentum hyperparameter, scalar
    learning_rate -- the learning rate, scalar
    
    Returns:
    parameters -- python dictionary containing your updated parameters 
    v -- python dictionary containing your updated velocities
    """

    L = len(parameters) // 2 # number of layers in the neural networks
    
    # Momentum update for each parameter
    for l in range(L):
        
        ### START CODE HERE ### (approx. 4 lines)
        # compute velocities
        v['dW' + str(l + 1)] = beta * v['dW' + str(l + 1)] + (1. - beta) * grads['dW' + str(l + 1)]
        v['db' + str(l + 1)] = beta * v['db' + str(l + 1)] + (1. - beta) * grads['db' + str(l + 1)]
        # update parameters
        parameters['W' + str(l + 1)] = parameters['W' + str(l + 1)] - learning_rate * v['dW' + str(l + 1)]
        parameters['b' + str(l + 1)] = parameters['b' + str(l + 1)] - learning_rate * v['db' + str(l + 1)]
        ### END CODE HERE ###
        
    return parameters, v
```
###3.RMSprop(均方根)
RMSprop全称为 root mean square prop 均方根。他也可以用来加速梯度下降
####公式:
$ S_{dw} = \beta S_{dw} + (1 - \beta)(dw)^2 $
$ S_{db} = \beta S_{db} + (1 - \beta)(db)^2 $
####参数更新
$ W = W - \alpha \frac{dw}{\sqrt(S_{dw} + \epsilon)}$
$ b = b - \alpha \frac{db}{\sqrt(S_{db} + \epsilon )}$
$ \epsilon $防止分母为0.一般为很小的数, $10^{-8}$

###4.Adam
Adam算法是训练神经网络最有效的优化算法之一,它结合了Momentum和RMSprop.

####公式
$V_{dw} = \beta_1 V_{dw} + (1-\beta_1)dw $
$V_{dw}^{corrected} = \frac{V_{dw}}{(1-\beta_1^t)}$
$S_{dw} = \beta_2 S_{dw} + (1-\beta_2)(dw)^2$
$S_{dw}^{corrected} = \frac{S_{dw}}{1-\beta_2^t}$
$W = W - \alpha \frac{V_{dw}}{\sqrt( S_{dw} + \epsilon)}$

b同理,这里不再列出

这里我们可以看到,有了两个参数, $ \beta_1$ 和 $\beta_2$ ,通常情况下我们让
$ \beta_1 = 0.9  \beta_2 = 0.999   \epsilon = 10 ^{-8}$

```python
# GRADED FUNCTION: update_parameters_with_adam

def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,
    beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):
    """
    Update parameters using Adam
    
    Arguments:
    parameters -- python dictionary containing your parameters:
                    parameters['W' + str(l)] = Wl
                    parameters['b' + str(l)] = bl
    grads -- python dictionary containing your gradients for each parameters:
                    grads['dW' + str(l)] = dWl
                    grads['db' + str(l)] = dbl
    v -- Adam variable, moving average of the first gradient, python dictionary
    s -- Adam variable, moving average of the squared gradient, python dictionary
    learning_rate -- the learning rate, scalar.
    beta1 -- Exponential decay hyperparameter for the first moment estimates 
    beta2 -- Exponential decay hyperparameter for the second moment estimates 
    epsilon -- hyperparameter preventing division by zero in Adam updates

    Returns:
    parameters -- python dictionary containing your updated parameters 
    v -- Adam variable, moving average of the first gradient, python dictionary
    s -- Adam variable, moving average of the squared gradient, python dictionary
    """
    
    L = len(parameters) // 2                 # number of layers in the neural networks
    v_corrected = {}                         # Initializing first moment estimate, python dictionary
    s_corrected = {}                         # Initializing second moment estimate, python dictionary
    
    # Perform Adam update on all parameters
    for l in range(L):
        # Moving average of the gradients. Inputs: "v, grads, beta1". Output: "v".
        ### START CODE HERE ### (approx. 2 lines)
        v['dW' + str(l + 1)] = beta1 * v['dW' + str(l + 1)] + (1. - beta1) * grads['dW' + str(l + 1)]
        v['db' + str(l + 1)] = beta1 * v['db' + str(l + 1)] + (1. - beta1) * grads['db' + str(l + 1)]
        ### END CODE HERE ###

        # Compute bias-corrected first moment estimate. Inputs: "v, beta1, t". Output: "v_corrected".
        ### START CODE HERE ### (approx. 2 lines)
        v_corrected['dW' + str(l + 1)] = v['dW' + str(l + 1)] / (1. - beta1**t)
        v_corrected['db' + str(l + 1)] = v['db' + str(l + 1)] / (1. - beta1**t)
        ### END CODE HERE ###

        # Moving average of the squared gradients. Inputs: "s, grads, beta2". Output: "s".
        ### START CODE HERE ### (approx. 2 lines)
        s['dW' + str(l + 1)] = beta2 * s['dW' + str(l + 1)] + (1. - beta2) * grads['dW' + str(l + 1)]**2
        s['db' + str(l + 1)] = beta2 * s['db' + str(l + 1)] + (1. - beta2) * grads['db' + str(l + 1)]**2
        ### END CODE HERE ###

        # Compute bias-corrected second raw moment estimate. Inputs: "s, beta2, t". Output: "s_corrected".
        ### START CODE HERE ### (approx. 2 lines)
        s_corrected['dW' + str(l + 1)] = s['dW' + str(l + 1)] / (1. - beta2**t)
        s_corrected['db' + str(l + 1)] = s['db' + str(l + 1)] / (1. - beta2**t)
        ### END CODE HERE ###

        # Update parameters. Inputs: "parameters, learning_rate, v_corrected, s_corrected, epsilon". Output: "parameters".
        ### START CODE HERE ### (approx. 2 lines)
        parameters['W' + str(l + 1)] = parameters['W' + str(l + 1)] - learning_rate * v_corrected['dW' + str(l + 1)] / \
        (np.sqrt(s_corrected['dW' + str(l + 1)]) + epsilon)
        parameters['b' + str(l + 1)] = parameters['b' + str(l + 1)] - learning_rate * v_corrected['db' + str(l + 1)] / \
        (np.sqrt(s_corrected['db' + str(l + 1)]) + epsilon)
        ### END CODE HERE ###

    return parameters, v, s
```