---
title: 先验概率、后验概率、最大似然估计(MLE)、最大后验估计(MAP)
copyright: true
mathjax: true
tags: 概率与统计
categories: 数学
abbrlink: d6cf3a1e
date: 2018-09-13 21:09:53
updated:
---

##概率与统计

概率和统计是两个看似相近的概念，但是其实研究的问题刚好相反。

概率研究的问题是,已知一个模型和参数,怎么去预测这个模型产生的结果。也就是根据参数和模型去推数据。

统计则刚好相反,统计是我有一堆数据,我怎么利用这堆数据去推测模型和参数。

** 概率是已知参数和模型,去推测结果；而统计是已知很多数据,去推模型和参数**

<!--more-->

##先验概率、后验概率、似然函数

###先验概率

简单理解:**在事件发生之前,根据以往的经验推测的与该事件相关的概率就是先验概率,而在事件(试验)真的发生之后,通过事件或试验的结果可以修正先验概率,从而得到后验概率**

###后验概率

后验概率:**在事件已经发生,要求这件事情发生的原因是由某个因素引起的可能性的大小**。(有果求因)

###举几个例子

####抛硬币

抛硬币时抛出正面的概率有多大？假如事前关于这枚硬币我们没有任何信息,主观上我们会认为是1/2.那么这里的1/2就是一个先验概率。但在经过一系列的实验结果我们发现正面朝上的概率可能不是1/2了(因为还会受到硬币的质量、重量分布等影响),通过一系列数据得到的修正了先验概率,就是后验概率

####山洞

假如你在一个山洞里,这个山洞里可能有熊可能也没有,记你觉得山洞里有熊的时间为$X$;然后你也许还听到山洞里传来熊叫声,记听到吼声为时间$Y$.那么你认为山洞里有熊的概率为$P(X)$,这就是先验概率；当你听到山洞里有熊叫声之后，你认为有熊的概率就是$p(X|Y)$,这个就是后验概率.

###似然函数

**似然函数**：是根据已知结果去推测固有属性的可能性。

对于这个函数$ P(x|\theta)$

如果已知参数$\theta,x$是变量,这个函数叫做概率函数(probability function),** 他描述对于不同样本x,他发生的概率是多少**

如果已知$x,\theta$是变量,这个函数就叫做似然函数，** 他描述对于不同的模型参数,样本点x的概率是多少**.

即** 我们以前计算的概率是已知参数和模型,去计算某个样本发生的概率是多少;而似然函数所计算的是已知很多样本数据X,而去估计他的模型参数是多少**

** 还是硬币的模型**

我们拿到一枚硬币,想知道抛出这枚硬币正面出现的概率$p$为多少？这是一个统计问题,而我们上面说过了统计问题是需要很多数据的。于是我们用这枚硬币做了十次实验,得到数据x:"反正正正正反正正正反"，我们想求的正面朝上的概率$p$是模型的参数,那么对于实验结果x的似然函数是多少呢？

$L(\theta) = \Pi_{i=1}^n p(x_i|\theta) = (1- \theta)^3 \times \theta^7 $ (假设扔硬币是二项分布)。这就是已知x,将$\theta$作为参数的一个似然函数。

这有点像“一菜两吃”的意思。其实这样的形式我们以前也不是没遇到过。例如$ f(x,y) = x^y$;如果x是已经确定的(x=2)，这就是$f(y) = x^y$是一个指数函数；如果y已知的话(y=2),这就是$f(x) = x^2$这就是个二次函数了。**同一个函数形式,我们通过不同的变量观察得到了不同的名字**

###三者之间的关系

我们上面说到了先验概率、后验概率以及似然函数,那么三者有什么关系呢？对于上面那个抛硬币的例子,抛出正面硬币的概率应该是一个概率分布,他不可能是一个单一值1/2(我们说过会受很多其他因素的影响),可能有很高的概率1/2,也有其他的。那么这个概率的分布用函数来表示就是一个似然函数,所以似然函数也被成为“分布的分布”，用公式来表示:

** 后验概率 ∝ 似然函数 $ \times $先验概率 ** (即后验概率正比于似然函数和先验概率的乘积)

为什么会是这个关系呢？这个还要从我们的贝叶斯公式讲起,请继续往下看。

###条件概率和似然函数有什么区别？

##最大似然估计(MLE)

上面我们提到的例子,即求硬币正面朝上的概率p.我们根据样本x得到了似然函数

$L(\theta) = (1- \theta)^3 \times \theta^7$

而最大似然估计,顾名思义就是要最大化这个函数。先画出图像:{% asset_img 2.png %}

可以看出在 $ \theta = 0.7$时,似然函数取得最大值。这样我们就完成了最大似然估计。

[关于最大似然估计](https://www.matongxue.com/madocs/447.html).

##贝叶斯公式
[怎么样用非数学语言讲解贝叶斯定理？](https://www.matongxue.com/madocs/279.html)
$ P(A|B) = \frac{P(B|A)\times P(A)}{P(B)}$

全概率公式: $ P(A) = \sum_{i=1}^nP(A|S_i)P(S_i)$其中$S$为样本空间的一个划分。

全概率公式告诉我们,当直接求P(A)不好求时,我们知道样本空间的一个划分$S_i$,同时知道事件A在每个事件$S_i$发生的条件下发生的条件概率$P(A|S_i)$,那么以此我们就可以求出A事件发生的概率。

将贝叶斯公式依据全概率公式展开得:

$ P(A|B) = \frac{P(B|A)\times P(A)}{P(B)}$

$ P(A_j|B)=\frac{P(B|A_j)P(A_j)}{\sum_{i=1}^n P(B|A_i)P(A_i)}$

贝叶斯公式还可以表述为:{% asset_img 1.gif %}

###贝叶斯公式的直观解释
{%asset_img 7.png %}
{%asset_img 8.png %}
{%asset_img 9.png %}
可见$ P(D) = P(AD) + P(DB) + P(CD)$
由条件概率也可以写成: 
$ P(D) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)$
算出来的结果就是事件D在样本空间S下发生的概率.
{%asset_img 10.png %}
先发生A在发生D的事件
{%asset_img 11.png %}
计算事件在样本空间下的概率
{%asset_img 12.png %}
那么M发生在A中的概率
$ P(A|D) = \frac{P(AD)}{P(D)}$
$= \frac{P(D|A)P(A)}{P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)}$，这就是贝叶斯公式
##最大后验估计(MAP)

对于上面的似然函数,我们最大化后得到$\theta$ = 0.7,即我们扔了十次硬币,七次正面朝上,而且我们得到的概率也是0.7,这好像很合理。但是有人可能会说硬币一般都是均匀了,就算的做实验结果是"反正正正正反正正正反"我也不信$\theta = 0.7$

这里就包含了贝叶斯学派的思想了————要考虑先验概率,由此引入了最大后验概率估计。
**最大似然估计是求参数$\theta$,使似然函数$P(x|\theta)$最大。最大后验概率估计则是想求$\theta$使得$P(x|\theta)P(\theta)$最大,也就是说,我们求得的$\theta$不仅要使得似然函数$L(\theta)$最大,同时它自己出现的先验概率也得大才行.** (这里有点像正则化当中加入惩罚项一样,不过正则化是用加法,而这里我们是利用乘法)。
最大后验概率估计(MAP)其实是在最大化 $P(\theta|x) = \frac{P(x|\theta)P(\theta)}{P(x)}$,$P(x)$是一个已知值,因为这里是通过实验得到的大数据集来计算得到的P(x)值,所以就可以忽略分母了。**$P(\theta|x) $即后验概率,表示x已经出现,要求$\theta$取什么值使得$P(\theta|x)最大$**,这就是最大后验概率估计的由来. 
对于投硬币的例子来看，我们认为（”先验地知道“）θθ取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识,例如假设$P(\theta)为均值0.5,方差0.1的高斯函数。$
{%asset_img 3.png %}
则$P(x|\theta)P(\theta)$的图像为{%asset_img 4.png %}
**注意到,此时函数最大值$\theta$已经向左偏移,不再是0.7了，实际上$\theta = 0.558$时取得最值。即,用最大后验概率估计,得到$\theta = 0.558$**

最后，那要怎样才能说服一个贝叶斯派相信$ \theta = 0.7 $呢？你得多做点实验。。

如果做了1000次实验，其中700次都是正面向上，这时似然函数为
{% asset_img 5.png %}
如果仍然设$P(\theta)$为均值0.5m方差0.1的高斯函数,$P(x|\theta)P(\theta)$的函数图像为:
{% asset_img 6.png %}
在$\theta = 0.696$ 处,取得最大值。
这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把$\theta$估计在0.7附近了。
PS. 要是遇上了顽固的贝叶斯派，认为$P(\theta=0.5)=1$ ，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是$\theta=0.5$。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）
